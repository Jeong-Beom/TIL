## 데이터 전처리 : 데이터 생성, 데이터 정제

ㆍ**데이터 마이닝** : 대용량의 데이터로부터 패턴을 파악하고 의미있는 정보를 만드는 것

ㆍ**머신러닝** : 데이터 마이닝을 통해 발굴한 정보를 바탕으로 예측 모델 등 서비스 제작

ㆍ데이터 기반의 의사결정은 **객관성**과 **합리성**을 상승시키고, 새로운 관점을 제공해줄 수 있음.

ㆍ**데이터 생성** 

1. 요약변수 : 수집된 변수를 분석의목적에 맞게 종합(aggregate)한 변수 / 단어빈도, 상품별 구매금액, 상품별 구매량

2. 파생변수 : 특정한 의미를 갖는 작위적 정의에 의한 변수 / 매우 주관적이므로 논리적 타당성을 갖추어야함.

   구매상품의 다양성 변수, 가격선호대, 라이프 스타일 변수, 영화 인기도

ㆍ**데이터 정제**

1. 결측값의 이해 : 기록누락, 미응답, 수집오류 등의 이유로 결측이 발생 / 결측값이 포함된 자료라도 나머지 변수의 값들은

   의미있는 정보이므로, 정보의 손실을 최소화하도록 결측을 처리하는 것이 바람직함.

   - 결측값 처리법 

     - 완전제거법(list-wise deletion) : 결측값이 하나라도 포함되어 있으면 해당 행을 완전히 삭제

     - 평균대체법(mean value imputation) : 결측값을 해당 변수의 나머지값들의 평균으로 대체 / 추정량의 표준오차가 과소추정됨.

     - 핫덱대체법(hot deck imputation) : 동일한 데이터내에서 결측값이 발생한 관찰치와 유사한 특성을 가진 

       다른 관찰치 정보를 이용하여 대체하는 방법

     - 그 밖의 결측값 처리법 : Regression imputatuion, KNN imputation 등(모델을 이용한 결측값 처리방법)

2. 이상값의 이해 

   - 이상값은 다른 데이터와 동떨어진 것을 말함

   - 다른 자료값들에 비해 멀리 떨어져 있지만 의미가 있는 값일 수도 있고, 단순히 입력오류로 발생한 값일 수도 있음

   - **이상값의 탐지**: 

     - Tukey의 IQR 및 상자그림 활용 : 4분위수를 기준으로 그래프를 그리는 상자그림을 통해 이상치의 수준을 한눈에 확인이 가능

     - 표준화 점수(Z-score) : 표준화 점수의 절대값이 2, 3보다 큰 경우를 이상값으로 진단

   - **이상값 처리방법** :

     - 이상값 제외(trimming) : 처리는 간단하지만, 정보손실이 발생하고 추정량 왜곡이 생길 수 있음
     - 이상값 대체(winsorization) : 이상값을 정상값 중 최대 또는 최소 등으로 대체하는 방식
     - 변수 변환 : 자료값 전체에 로그변환(1, 10, 100 → 1, 2, 3), 제곱근(1, 4, 9 → 1, 2, 3) 변환 등을 적용

3. 연속형 자료의 범주화

   - 변수구간화(binning) : 연속형 변수를 구간을 이용하여 범주화 하는 과정
     - 효과  : 이상치 문제를 완화, 결측치 처리방법이 될 수 있음, 변수간 관계가 단순화되어 과적합 방지 및 결과해석이 용이



## 데이터 전처리 : 데이터 변환, 데이터 결합

ㆍ**데이터 변환** : 자료 변환을 통해 자료의 해석을 쉽고 풍부하게 하기 위한 과정 

1. 목적 : 분포의 대칭화, 산포를(정규분포와 비슷한 모양) 비슷하게 하고, 변수 간 관계를 단순하게(비선형관계를 선형관계로) 하기 위해서 실시

2. 데이터 변환 : 

   - 제곱근 변환(분포를 왼쪽방향으로 끌어와줌), 제곱변환(분포를 오른쪽 방향으로 끌어와줌)

   - 로그변환(분포를 왼쪽방향으로 끌어와줌), 지수변환(분포를 오른쪽 방향으로 끌어와줌)
   - 박스콕스 변환(Box-Cox Transform) : 제곱근 유형으로 변환을 함(지수, 로그, 지수변환이 모두 가능)

ㆍ**데이터 결합** : 2개 이상의 데이터 테이블을 결합하는 것,

1. 이너조인(inner join) : 두 테이블에 키(key)가 공통으로 존재하는 레코드(record)만 결합
2. 풀 아우터 조인(full outer join) : 두 테이블 중 어느 한쪽이라도 존재하는 키에 대한 레코드를 모두 결합
3. 레프트 조인(left join) : 왼쪽 테이블에 존재하는 키에 대한 레코드를 결합(왼쪽 테이블에 존재하는 키들에 대해 레코드를 결합)
4. 라이트 조인(right join) : 오른쪽 테이블에 존재하는 키에 대한 레코드를 결합(오른쪽 테이블에 존재하는 키들에 대한 레코드를 결합)



## 머신러닝의 기본 개념 및 방법론의 분류

ㆍ**머신러닝** : 

1. 컴퓨터 시스템에 명시적으로 프로그래밍 하지 않더라도 데이터를 스스로 학습하여 문제를 해결할 수 있게하는 기술
2. 사람이 인지하기 어려운 복잡한 규칙과 패턴을 파악하여 의미있는 결과를 얻을 수 있음

ㆍ발전과정 : 머신러닝 알고리즘의 발전 + 컴퓨팅 성능의 발전 + 대용량 데이터의 축적 및 관리기술의 발전 → 머신러닝의 활용 증가

ㆍ**방법론** :

1. 지도학습(Supervised Learning) 
   - 라벨이 있는 훈련용 데이터에서, 여러 특성변수를 이용하여 목표변수인 라벨을 예측하도록 모델을 학습함
   - 라벨의 데이터 타입에 따라 라벨이 연속형이면 **회귀(Regression)** 알고리즘, 범주형이면 **분류(Classification)**알고리즘으로 구분
   - 대표 알고리즘 
     - Linear Regression, k-nearest Neighbors, Logistic Regression, Softmax Regression - 분류용 알고리즘
     - Decision Tree, SVM, Random Forest, Boosting, Neural Network, Deep Learning - 회귀와 분류가 모두 가능
2. 비지도학습(Unsupervised Learning)
   - 라벨이 없는 훈련용 데이터에서 특징 변수들 간의 관계나 유사성을 기반으로 의미있는 패턴을 추출
   - 자율학습이라고도하며, **군집화(clustering)**, **차원축소(dimension reduction)**, **추천시스템(recommendation)**등에 활용됨
   - 대표 알고리즘
     - k-means Clustering, Hierarchical Clustering, PCA, t-SNE, Apriori, Auto-Encoders

3. 강화학습(Reinforcement Learning)
   - 행동하는 주체(agent)가 있고, 행동을 했을 때의 상태(state)와 보상(reward)을 바꿔주는 환경(environment)로 구성됨
   - 주체가 매번 어떠한 행동(action)을 하면 환경에 의해 상태와 보상이 바뀌면서 주체는 보상이 가장 커지는 방향으로 학습
   - 대표 알고리즘
     - SARSA, Q-Learning



## 머신러닝 모델의 분석 절차

ㆍ모델 기반 지도학습 알고리즘의 일반적인 분석 절차

- 주어진 데이터 전처리 및 탐색 / 적절한 모델을 선택 / 주어진 데이터로 모델을 훈련시킴 / 모델을 적용하여 새로운 대이터를 예측
- 과대적합을 이해하고 잘 컨트롤하는 것이 핵심임

ㆍ**과대적합(overfitting)의 문제**

- 주어진 자료는 거의 완벽한 예측이 가능하지만, 미래의 새로운 자료에 대한 예측력이 떨어지는 문제
- 복잡한 알고리즘을 사용하여 데이터를 훈련하는 경우 과대적합 문제를 항상 염두에 두어야 함

ㆍ모델의 검증 및 평가 개요

- 필요성 
  - 과대적합을 막고 일반화 오차를 줄이기 위해서는 , 새로운 데이터에 얼마나 잘 일반화될지를 파악해야함
  - 모델 적합에 사용된 자료를 평가를 위해 재활용하지 않고, 평가만을 위한 데이터를 확보할 필요가 있음
- 데이터를 분할하는 방식
  - Hold-out 방식 : 세 그룹으로 랜덤하게 분할한 뒤, 목적에 따라 각각 모델의 훈련, 검증, 평가에 활용함
    - 훈련 데이터(Training Data : 모델의 학습에 사용되는 데이터
    - 검증 데이터(Validation Data) 
      1. 훈련자료로 적합되는 모델을 최적의 성능으로 튜닝하기 위해 사용되는 자료
      2. 훈련에 필요한 하이퍼 파라미터(hyperparameter)를 조정하거나, 변수선택(model selecting)등에 이용
    - 평가 데이터(Test Data) : 훈련 및 검증자료로 적합된 최종모형이 새로운 자료에 대하여 얼마나 좋은 성과를 가지는지 평가
  - K-fld 교차검증(Cross-validation)방식 : 자료의 수가 충분하지 않는 경우에 주로 사용하는 방식
    - 자료를 균등하게 k개의 그룹으로 분할 / 각 j에 대하여, j번째 그룹을 제외한 나머지 k-1개 그룹의 자료를 이용하여 적합
    - j번째 그룹의 자료에 적합된 모델을 적용한 뒤 예측오차를 구함
    - j = 1, ...., k에 대하여 위의 과정을 반복한 뒤, k개의 예측오차의 평균을 구함
    - 예측오차의 평균값을 기준으로, 모델의 검증 또는 평가를 수행

ㆍ**편향 - 분산 트레이드오프(Bias - Variance Trade off)**

- 모델의 복잡한 정도에 따라 훈련데이터와 평가데이터의 예측오차는 2차방정식의 모양을 가지게됨.
- 모델이 복잡하면 과대적합, 너무 간소화되면 과소적합됨 → 적절한 값을 찾는 것이 중요

ㆍ과대적합을 막기위한 방법

- 훈련데이터를많이 확보 / 모델의 복잡도를 낮춤(특성 변수의 수를 줄이거나 차원축소 / 파라미터에 규제를 적용)



## 머신러닝 모델의 평가지표

ㆍ**회귀(Regression) 모델의 평가지표**

- **RMSE(Root mean square error - 오차를 평균한 것)** / **R-square(결정계수)**
- 결정계수 값은 클수록 좋고, 작을수록 모델의 성능이 좋지않음을 나타냄(0~1사이의 값을 가짐)

- **MAE(Root mean square error)** : 오차의 부호만 제거해서 이를 평균한 값 / MAE가 10이면 오차가 평균적으로 10발생한다고 이해
- **MAPE(mean average percentage error)** : 실제 값 대비 오차가 차지하는 비중이 평균적으로 얼마인지 확인 / 작을수록 좋음

ㆍ**분류(Classification)모델의 평가지표**

- **정오분류표(Confusion Matrix)** : 실제자료와 모형에 의한 예측의 비율을 나타내는 표
  - 정확도, 정분류율(Accuracy) : 전체자료들 중에 실제값을 맞춘 비중 / T와 N의 비율이 편향된 경우 모델의 성능을 평가하기가 어려움
  - 1종오류와 2종오류의 가중치가 다른 경우 큰 문제가 될 수 있음
  - 정밀도(Precision) : T로 예측한 것 중에서 실제 범주도 T인 데이터의 비율
  - 재현율(Recall) : 실제 범주가 T인 것 중에서 T로 예측된 데이터의 비율
  - ROC(Receiver operating characteristic) 도표
    - 분류의 결정임계값(threshold)에 따라 달라지는 TPR(민감도, sensitivity)과 FPR(특이도, specificity)의 조합으로 나타낸 도표
    - TPR : 1인 케이스에 대해 1로 잘 예측한 비율 / FPR : 0인 케이스에 대해 1로 잘못 예측한 비율
    - 임계값이 1이면, FPR, TPR = 0, 0 / 임계값을 1에서 0으로 낮춰감에 따라 FPR과 TPR은 동시에 증가
    - FDR이 증가하는 정도보다 TPR이 빠르게 증가하면 이상적 : 왼쪽 위 꼭지점에 가까울수록 좋음.
  - AUC(Area Under the Curve)
    - ROC곡선 아래의 면적 / 가운데 대각선의 직선은 랜덤한 수준의 이진분류에 대응되며, 이 경우 AUC는 0.5임
    - 1에 가까울수록 좋은 수치, FPR이 작을때 얼마나 큰 TPR을 얻는지에 따라 결정됨



## 특성공학 : 개요, 특성 선택(Feature Selection) 방법론

ㆍ**특성선택** : 전체 특성변수 중 최적의 조합을 선택하는 문제

ㆍ**특성추출** : 특성변수들을 적절하게 조합하여 새로운 특성변수를 만드는 방법

ㆍ**특성공간 차원축소의 필요성**

- 모델의 해석력 향상 / 모델의 훈련시간 단축 / 차원의 저주(차원이 증가할 수록 정보를 파악하기 어려워지는 경향) 방지
- 과적합(overfitting)에 의한 일반화 오차를 줄여 성능 향상

ㆍ특성공학의 방법론은 크게 특성 선택(feature selection)방법과 특성추출(feature extraction)방법으로 구분할 수 있음

ㆍ**특성선택의 방법론**

- 주어진 특성변수들 가운데 가장 좋은 특성변수의 조합만 선택 / 불필요한 특성변수를 제거

- Filterinf, Wrapper, Embedded 방식으로 분류가능

  - **filter** : 순위를 매긴 후 높은 순위에 해당하는 변수들만 선택하는 방식

    - 각 특성변수 Xi와 목표변수 Y와의 연관성을 측정 후, 목표변수를 잘 설명할 수 있는 특성변수만을 선택
    - Xi와 Y의 1:1 관계로만 연관성을 판단
    - 연관성 파악을 위해 t-test, chi-square test, information gain등의 지표가 활용됨
    - 계산비용이 적고 속도가 빠름 / 특성변수간의 상호작용을 고려하지 않음

  - **wrapper** : n개의 후보군들의 조합을 뽑아서 모델에 훈련시키면서 가장 최적의 조합을 찾아서 선택하는 방식
    - 다양한 특성변수의 조합에 대해 목표변수를 예측하기 위한 알고리즘을 훈련하고, cross-validation등의 방법으로 훈련된

      모델의 예측력을 평가함. 그 결과를 비교하여 최적화된 특성변수의 조합을 찾는 방법

    - 특성변수의 조합이 바뀔때마다 모델을 학습함

    - 특성변수에 중복된 정보가 많은 경우 이를 효과적으로 제거함

    - 대표적인 방법으로 순차탐색법인 forward selection, backward selection, stepswise selection등이 있음

    - 특성변수 간의 상호작용을 고려함, 주어진 학습 알고리즘에 대해 항상 최적의 특성변수 조합을 찾음

    - 모델을 학습해야 하므로, 계산비용이 크고 속도가 느림, 과적합(overfitting)의 가능성이 있음.

  - **embedded** : 특정변수를 자체적으로 선택하는 모델을 사용
    - 학습알고리즘 자체에 feature seletion을 포함



## 특성공학 : 특성추출(Feature Extraction) 방법론

ㆍ**주요 특성추출방법**

- **PCA(Principal component analysis) : 주성분 분석**
  - 연관되어 있는 변수들이 관찰되었을 때, 전체적으로 가지고 있는 정보들을 최대한 확보하는 적은 수의 새로운 변수를 만드는 방법
  - 목적 
    - 자료에서 변동이 큰 축을 탐색함 / 변수들에 담긴 정보의 손실을 최소화하면서 차원을 축소
    - 서로 상관이 없거나 독립적인 새로운 변수인 주성분을 통해 데이터의 해석을 용이하게 함
  - 아이디어
    - k개의 특성변수 x1, ...., xk의 주성분이 y1, .... , yk라면 이들은 아래의 선형결합식으로 표현가능
    - y1 = l1x1 + l21x2 + .... + lnxn ....... + α
  - 기하학적 의미
    - 주성분 축은 원래 변수들의 좌표축이 직교 회전 변환된 것으로 해석할 수 있음
    - 첫번째 주성분축은 데이터의 변동이 가장 커지는 축임
    - 두번째 주성분축은 첫번째 주성분축과 직교하며 첫번째 주성분축 다음으로 데이터의 변동이 큰 축을 나타냄
    - 각 관찰치 별 주성분 점수는 대응하는 원자료 값들의 주성분 좌표축에서의 좌표값에 해당함
    - 자료들의 공분산 행렬이 대각행렬이 되도록 회전한 것으로 해석 가능

- **SVD(Singular Value Decomposition) : 특성값 분해**
  - 임의의 n x d 행렬 A는 A = UΣV^T로 분해가능함
  - A = UΣV^T  = (루트λ1) * u1 * v1^T + (루트λ2) * u2 * v2^T + ..... + (루트λm) * um * vm^T + .... + (루트λr) * ur * vr^T
  - 정보가 많은 순서대로 m개만 사용하여 근사하는 경우 m계수 근사라고 함.
  - 주성분 분성(PCA)와 특성값 분해의 관계
    - A의 오른쪽 특성벡터는 A의 공분산 행렬의 고유벡터와 동일함
    - 자료 행렬에 대한 특성값 분해로 주성분을 도출 가능
- **LDA(Linear discriminant analysis)**
- **NMF(Non-negative matrix factoriztion)**

