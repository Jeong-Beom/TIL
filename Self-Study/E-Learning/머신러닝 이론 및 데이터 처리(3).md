## 의사결정나무 모델 : 분류 나무(Classification Tree)

ㆍ지도 학습용 데이터가 주어졌을 때 특성변수 특징을 이용해서 분할해가는 과정 / 나무모양처럼 도식화

ㆍ**의사결정 나무모형**

- 의사결정규칙(decision rule)을 나무 구조로 도표화하여 관심대상이 되는 집단을몇 개의 소집단으로 분할하는 방식

- 구조

  - 뿌리마디(root node) : 시작되는 마디로 전체 자료로 구성됨
  - 자식마디(child node) : 하나의 마디로부터 분리되어 나간 2개 이상의 마디들
  - 부모마디(parent node) : 주어진 마디의 상위마디
  - 끝마디(terminal node) : 자식마디가 없는 마디
  - 중간마디(internal node) : 부모마디와 자식마디가 모두 있는 마디
  - 깊이(depth) : 뿌리마디부터 끝마디까지 중간마디의 수

- 종류

  - 의사결정나무 알고리즘은 CHAID, CART, C%.0, QUEST등과 이들의 장점을 결합한 다양한 알고리즘이 존재
  - **CART** : 분리나무 - 지니불순도 / 회귀나무 - 분산감소량을 이용하여 분리함
    - 항상 이진분리
    - 개별 특성변수 및 특성변수의 선형결합형태의 분리기준도 가능
  - **C4.5, C5.0** : 엔트로피 불순도로 구한 정보이득으로 분리
    - 범주형 특성변수는 다진분리 / 연속형 특성변수는 이진분리
  - **CHAID** : 분류나무 - 카이제곱 통계량 / 회귀나무 - ANOVA F통계량
    - 다진분리 / 변수간 통계적 관계에 기반

- 분석절차

  - 나무의 성장(growing) : 각 마디에서 적절한 최적의 분리규칙(splitting rule)을 찾아 나무를 성장시킴

    정지규칙(stopping rule)을 만족하는 경우에는 성장을 중단

    - 상위노드로부터 하위노드로 나무구조를 형성하는 매 단계마다 분리규칙(어느 특성변수로 어떻게 분할할 것인가)

      을 선택함

    - 분리규칙의 형태(이진분할의 경우)

      1. 연속형 특성변수 : 분리에 사용될 특성변수 X와 분리점 c를 이용하여 X < c면 왼쪽 자식마디, 그렇지 않으면

         오른쪽 자식마디로 자료를 분리

      2. 범주형 특성변수 : 분리에 사용될 특성변수 X가 가지는 전체범주 중 부분집합인 A를 이용하여 X ∈ A면 왼쪽 자식마디

         그렇지 않으면 오른쪽 자식마디로 자료를 분리

    - 분류기준은 해당 노드에서 그 기준으로 하위노드를 분기하였을 때, 하위 노드 내에서는 동질성이 하위 노드간에는 이질성이

      가장 커지도록 선택됨

    - 분류나무의 분리규칙  탐색

      1. 불순도 : Y의 범주가 j = 1, .... , C로 구성될 때, t노드에서의 불순도 imp(t)는 다음과 같이 정의됨

         지니불순도(gini impurity)  / 엔트로피 불순도(entropy impuritiy)

      2. 불순도가 클수록 자식노드 내 이질성이 큼을 의미함. 불순도가 가장 작아지는 방향으로 가지분할을 수행

      3. 불순도의 향상된 정도(Goodness of split) 

         어떤 부모마디 t에서 분리기준 s로 분리한 뒤 생성된 두 자식마디를 tL, tR이라고 할때

         G(s, t) = imp(t) - (N(tL) / N(t)) * imp(tL) - (N(tR) / N(t)) * imp(tR)

      4. 모든 특성변수와 그 특성변수의 모든 가능한 분리점에 대하여 G(s, t)를 구한뒤 G(s, t)가 가장 큰 특성변수 및

         분리점을 해당 마디에서의 분리기준으로 정함

  - 가지치기(pruning) : 오류율(error rate)을 크게 할 위험이 높거나 부적절한 추론 규칙을 가지고 있는 가지를 제거

  - 타당성 평가 : 평가자료(test data)를 이용하여 의사결정나무를 평가

  - 해석 및 예측 : 구축된 나무모형을 해석하고 분류 및 예측모형을 설정.



## 의사결정나무 모델 : 회귀모델(Regression Tree)

ㆍ회귀나무(Regrssion Tree)의 분리규칙 탐색

- 분산의 감소량

  - 각 그룹(자식노드)내에서의 목표변수의 분산이 작을수록, 그룹 내 이질성이 작은 것으로 볼 수 있음
  - 자식노드로 분리했을 때 분산(지니불순도와 비슷한 역할)의 감소량이 가장 커지도록 하는 분리규칙을 탐색

- ANOVA의 F 통계량

  - F값이 클수록 그룹(자식노드)간에 평균차이가 있다는 것이므로, 그룹간 이질성이 큰 것으로 볼 수 있음
  - F값이 가장 커지게 되는 분리규칙을 탐색

- 과적합 방지 방법

  - 지나치게 많은 마디를 가지는 의사결정나무는 새로운 자료에 적용할 때 예측오차가 매우 커지는 과적합상태가 됨

  - 이를 방지하기 위해 정지규칙을 설정

  - 정지규칙(stopping rule)

    - 다음의 경우에는 더 이상 분리하지 않고 나무가 성장을 멈추도록 함
    - 모든 자료의 목표변수 값이 동일할 때
    - 마디에 속하는 자료의 개수가 일정수준보다 적을 때
    - 뿌리마디로부터 깊이가 일정수준 이상일 때
    - 불순도의 감소량이 지정된 값보다 적을 때

  - 가지치기(pruning)

    - 성장이 끝난 나무의 가지를 제거하여 적당한 크기를 가지도록 함

    - 적당한 크기를 결정하는 방법은 검증용 자료(validation data)에 대한 예측오류가 가장 작은 나무모형을 찾는 것이

      일반적이며, 이 과정은 의사결정나무 모형 알고리즘 내에 자동화 되어 있는 경우가 많음

ㆍ의사결정나무모형 특징

- 장점
  - 이해하기 쉬운 규칙을 생성함
  - 특성변수 및 목표변수 둘 다 연속형, 범주형 자료 모두 취급함
  - 데이터의 전처리가 거의 필요하지 않음
  - 이상치에 덜 민감
  - 모형에 가정이 필요없는 비모수적 모형
- 단점
  - 훈련결과가 불안정함
  - 모든 분할은 축에 수직임
  - 나무가 깊어질수록 과적합으로 예측력이 저하되며, 해석이 어려워짐



## 추천 : 연관성 분석(Association Rule)

ㆍ장바구니 분석(Market basket analysis) / 지지도, 신뢰도, 향상도에 기반해서 작성을 하게 됨.

ㆍ**연관성 분석(Association Analysis)**

- 연관성 규칙을 통해 하나의 거래나 사건에 포함되어 있는 둘 이상의 품목 간 상호연관성을 발견하는 과정
- 고객이 동시에 구매하는 상품간의 관계를 분석한다는 의미에서 장바구니 분석(Market basket analysis)라고 함

ㆍ**연관규칙(Association Rule)**

- 항목들 간의 if item A → then item B형태로 표현되는 유용한 패턴 / {onion, potato} → {meat}

- 장바구니 하나에 포함된 품목(item)들의 집합 형태로 주어짐

ㆍ연관규칙을 파악하기 위한 측도

- 지지도(support)
  - 전체 구매 건수 가운데 상품 A와 B를 동시에 구매한 비율로, P[A * B]로 나타냄
  - 지지도(A→B) : (A와 B가 동시에 포함된 거래 수) / 전체 거래수
  - 상품 A 하나에 대한 지지도는 지지도(A) : A의 거래수 / 전체 거래 수

- 신뢰도(confidence)
  - 상품 A를 구매한 건수 가운데 B도 같이 구매한 비율로, 조건부 확률 P[A|B]
  - 신뢰도(A→B): (A와 B가 동시에 포함된 거래 수) / A의 거래수 = 지지도(A→B) / 지지도(A)

- 향상도(lift)

  - 전체에서 상품B를 구매한 비율에 비해, A를 구매한 고객이 B를 구매한 비율이 몇배인가를 의미하며, P[B|A] / P[B]로 나타냄
  - 향상도(A→B) : 신뢰도(A→B) / 지지도(B)
  - 향상도의 해석
    1. 향상도(A→B) = 1 : 상품 A와 상품 B의 구매는 상호연관성이 없음.
    2. 향상도(A→B) > 1 : 상품 A와 상품 B의 구매는 양의 영향력이 있음
    3. 향상도(A→B) < 1 : 상품 A와 상품 B의 구매는 음의 영향력이 있음

- 연역적 알고리즘

  - 품목들의 집합 별로 지지도, 신뢰도, 향상도 지표를 구해야 하는데, 품목의 수가 많을 때는 연관규칙의 탐색비용이 크게 증가함

  - 연역적 알고리즘은 더이상 탐색하지 않아도 될 품목의 조합을 찾고, 그 조합을 부분집합으로 갖는 품목의 집합들을 가지치기 하여

    효율적인 탐색을 하도록 함

  - 최소 지지도 가지치기(minimum support pruning, MSP) : 어떤 품목(집합)에 대한 지지도가 일정수준

    (문턱기준, threshold criterion)을 넘지 못하면 그 품목(집합)이 포함된 조합들은 더이상 탐색하지 않음

