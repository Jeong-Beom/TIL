{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "순환신경망(RNN: Recurrent Neural Network)\n",
    "음성인식 또는 문장번역시 사용가능 / 시계열데이터 예측 가능\n",
    "주요개념 : Embedding, SimpleRNN, LSTM, Conv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<OOV>': 1, 'you': 2, 'are': 3, 'the': 4, 'best': 5, 'nice': 6}\n",
      "------------------------------------------------------------------\n",
      "sequences: [[2, 3, 4, 5], [2, 3, 4, 6]]\n",
      "\n",
      "binary_vectors:\n",
      " [[0. 0. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 1. 1. 0. 1. 0. 0. 0.]]\n",
      "\n",
      "test sequences: [[2, 3, 4, 1]]\n"
     ]
    }
   ],
   "source": [
    "# Embedding층 : 단어(또는 데이터)를 벡터형태로 표현할 수 있음 -> 텍스트 분류의 가장 기본적인 층\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "texts = ['You are the Best', 'You are the Nice']\n",
    "tokenizer = Tokenizer(num_words = 10, oov_token = '<OOV>')\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "# 텍스트 데이터를 정수 인덱스 형태로 변환\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "# 이진형태로 인코딩\n",
    "binary_results = tokenizer.sequences_to_matrix(sequences, mode = 'binary')\n",
    "\n",
    "print(tokenizer.word_index)\n",
    "print('------------------------------------------------------------------')\n",
    "\n",
    "print(f'sequences: {sequences}\\n')\n",
    "print((f'binary_vectors:\\n {binary_results}\\n'))\n",
    "\n",
    "test_text = ['You are the One']\n",
    "test_sq = tokenizer.texts_to_sequences(test_text)\n",
    "\n",
    "print(f'test sequences: {test_sq}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "C:\\Users\\Bestc\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "C:\\Users\\Bestc\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "num_words = 10000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,) (25000,)\n",
      "(25000,) (25000,)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 형태확인\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before pad_sequences:  218\n",
      "After pad_sequences:  500\n"
     ]
    }
   ],
   "source": [
    "# imdb데이터는 이미 인코딩이 완료되어 있음.\n",
    "# 데이터를 동일한 길이로 맞추기\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "max_len = 500\n",
    "print('Before pad_sequences: ', len(X_train[0]))\n",
    "\n",
    "pad_X_train = pad_sequences(X_train, maxlen = max_len, padding = 'pre')\n",
    "pad_X_test = pad_sequences(X_test, maxlen = max_len, padding = 'pre')\n",
    "\n",
    "print('After pad_sequences: ', len(pad_X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 500, 32)           320000    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 16001     \n",
      "=================================================================\n",
      "Total params: 336,001\n",
      "Trainable params: 336,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 구성하기\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "# 해당층은 모델의 첫번째 층으로만 사용가능\n",
    "# Flatten층을 사용하기 위해 input_length를 전달\n",
    "# input_dim의 인자는 학습 데이터 셋에 사용한 단어의 개수\n",
    "# output_dim의 인자는 임베딩 벡터의 크기\n",
    "model.add(Embedding(input_dim = num_words, output_dim = 32, input_length = max_len))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.4576 - acc: 0.7735 - val_loss: 0.2966 - val_acc: 0.8796\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.2014 - acc: 0.9271 - val_loss: 0.2733 - val_acc: 0.8848\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 0.1052 - acc: 0.9703 - val_loss: 0.2913 - val_acc: 0.8868\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 0.0500 - acc: 0.9913 - val_loss: 0.3134 - val_acc: 0.8876\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 0.0236 - acc: 0.9976 - val_loss: 0.3411 - val_acc: 0.8820\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(pad_X_train, y_train, batch_size = 32, epochs = 5, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 2ms/step - loss: 0.3447 - acc: 0.8775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3446876108646393, 0.8775200247764587]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(pad_X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fe3bab233825460445dbfeea6dcd52ef5815a3fa13c858fea07ac830aa383284"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
