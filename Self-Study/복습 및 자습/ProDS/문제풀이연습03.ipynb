{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dataset.zip', 'Dataset_01.csv', 'Dataset_02.csv', 'Dataset_03.csv', 'Dataset_04.csv', 'Dataset_05.csv', 'Dataset_05_item_list.csv', 'Dataset_05_Mart_POS.csv', 'Dataset_06.csv', 'Dataset_07.csv', 'Dataset_08.csv', 'Dataset_09.csv', 'Dataset_10.csv', 'Dataset_11.csv', 'Dataset_12.csv', 'Dataset_13_test.csv', 'Dataset_13_train.csv', 'Dataset_14.csv', 'Dataset_15_item_list.csv', 'Dataset_15_Mart_POS.csv']\n"
     ]
    }
   ],
   "source": [
    "PATH = 'C:/Workspace/python/Data_Science/dataA/ProDS특강/'\n",
    "file_list = os.listdir(PATH)\n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4572 entries, 0 to 4571\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   TV            4562 non-null   float64\n",
      " 1   Radio         4568 non-null   float64\n",
      " 2   Social_Media  4566 non-null   float64\n",
      " 3   Influencer    4572 non-null   object \n",
      " 4   Sales         4566 non-null   float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 178.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data1=pd.read_csv(PATH + 'Dataset_01.csv')\n",
    "data1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.isna().sum().sum() # 결측치가 포함된 셀의 수\n",
    "(data1.isna().sum(axis=1)>=1).sum() # 결측치가 포함된 행의 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Social_Media    0.528906\n",
       "Name: Sales, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.columns\n",
    "var_list=['TV', 'Radio', 'Social_Media','Sales']\n",
    "q2=data1[var_list].corr().abs().drop('Sales')['Sales']\n",
    "q2.max() # 0.999497444941335 , 최대값\n",
    "q2.argmax() # 위치번호\n",
    "q2.idxmax()  # 최대값이 있는 인덱스명\n",
    "q2.nlargest(1) # TV    0.999497, 인덱스명+최대값\n",
    "q2.min() # 0.52890600264434 , 최소값\n",
    "q2.argmin() # 위치번호\n",
    "q2.idxmin()  # 최소값이 있는 인덱스명\n",
    "q2.nsmallest(1) # TV    0.999497, 인덱스명+최대값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.56256963, -0.00397039,  0.00496402])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.formula.api import ols \n",
    "from statsmodels.api import OLS, add_constant\n",
    "q3=data1.dropna()\n",
    "x_list=['TV', 'Radio', 'Social_Media']\n",
    "lm=LinearRegression(fit_intercept=True).fit(q3[x_list], q3.Sales)\n",
    "dir(lm) # 호출가능한 메서드들 확인\n",
    "lm.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Sales</td>      <th>  R-squared:         </th> <td>   0.999</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.999</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>1.505e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 11 Dec 2021</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:10:04</td>     <th>  Log-Likelihood:    </th> <td> -11366.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4546</td>      <th>  AIC:               </th> <td>2.274e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4542</td>      <th>  BIC:               </th> <td>2.277e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>    <td>   -0.1340</td> <td>    0.103</td> <td>   -1.303</td> <td> 0.193</td> <td>   -0.336</td> <td>    0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TV</th>           <td>    3.5626</td> <td>    0.003</td> <td> 1051.118</td> <td> 0.000</td> <td>    3.556</td> <td>    3.569</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Radio</th>        <td>   -0.0040</td> <td>    0.010</td> <td>   -0.406</td> <td> 0.685</td> <td>   -0.023</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Social_Media</th> <td>    0.0050</td> <td>    0.025</td> <td>    0.199</td> <td> 0.842</td> <td>   -0.044</td> <td>    0.054</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.056</td> <th>  Durbin-Watson:     </th> <td>   1.998</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.972</td> <th>  Jarque-Bera (JB):  </th> <td>   0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.001</td> <th>  Prob(JB):          </th> <td>   0.983</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.013</td> <th>  Cond. No.          </th> <td>    149.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  Sales   R-squared:                       0.999\n",
       "Model:                            OLS   Adj. R-squared:                  0.999\n",
       "Method:                 Least Squares   F-statistic:                 1.505e+06\n",
       "Date:                Sat, 11 Dec 2021   Prob (F-statistic):               0.00\n",
       "Time:                        10:10:04   Log-Likelihood:                -11366.\n",
       "No. Observations:                4546   AIC:                         2.274e+04\n",
       "Df Residuals:                    4542   BIC:                         2.277e+04\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "Intercept       -0.1340      0.103     -1.303      0.193      -0.336       0.068\n",
       "TV               3.5626      0.003   1051.118      0.000       3.556       3.569\n",
       "Radio           -0.0040      0.010     -0.406      0.685      -0.023       0.015\n",
       "Social_Media     0.0050      0.025      0.199      0.842      -0.044       0.054\n",
       "==============================================================================\n",
       "Omnibus:                        0.056   Durbin-Watson:                   1.998\n",
       "Prob(Omnibus):                  0.972   Jarque-Bera (JB):                0.034\n",
       "Skew:                          -0.001   Prob(JB):                        0.983\n",
       "Kurtosis:                       3.013   Cond. No.                         149.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "form1='Sales~'+'+'.join(x_list)\n",
    "form2='Sales~'+'+'.join(x_list)+'-1'\n",
    "ols1=ols(form1, data=q3).fit()\n",
    "ols1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Social_Media</th>\n",
       "      <th>Influencer</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>72.0</td>\n",
       "      <td>25.406596</td>\n",
       "      <td>3.215455</td>\n",
       "      <td>Micro</td>\n",
       "      <td>262.401171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1.380311</td>\n",
       "      <td>5.286681</td>\n",
       "      <td>Mega</td>\n",
       "      <td>80.940725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>88.0</td>\n",
       "      <td>26.009640</td>\n",
       "      <td>1.495601</td>\n",
       "      <td>Nano</td>\n",
       "      <td>321.046689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>39.0</td>\n",
       "      <td>4.856123</td>\n",
       "      <td>0.874163</td>\n",
       "      <td>Macro</td>\n",
       "      <td>131.077255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>64.0</td>\n",
       "      <td>23.081488</td>\n",
       "      <td>3.056298</td>\n",
       "      <td>Macro</td>\n",
       "      <td>219.568184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4433</th>\n",
       "      <td>50.0</td>\n",
       "      <td>22.728177</td>\n",
       "      <td>3.794120</td>\n",
       "      <td>Mega</td>\n",
       "      <td>184.040212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4448</th>\n",
       "      <td>82.0</td>\n",
       "      <td>28.920430</td>\n",
       "      <td>3.213067</td>\n",
       "      <td>Micro</td>\n",
       "      <td>285.392143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4452</th>\n",
       "      <td>36.0</td>\n",
       "      <td>15.393056</td>\n",
       "      <td>3.601162</td>\n",
       "      <td>Nano</td>\n",
       "      <td>119.220715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4477</th>\n",
       "      <td>61.0</td>\n",
       "      <td>20.789544</td>\n",
       "      <td>2.473938</td>\n",
       "      <td>Macro</td>\n",
       "      <td>225.822151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4569</th>\n",
       "      <td>44.0</td>\n",
       "      <td>19.800072</td>\n",
       "      <td>5.096192</td>\n",
       "      <td>Micro</td>\n",
       "      <td>163.631457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>219 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TV      Radio  Social_Media Influencer       Sales\n",
       "93    72.0  25.406596      3.215455      Micro  262.401171\n",
       "130   21.0   1.380311      5.286681       Mega   80.940725\n",
       "136   88.0  26.009640      1.495601       Nano  321.046689\n",
       "162   39.0   4.856123      0.874163      Macro  131.077255\n",
       "179   64.0  23.081488      3.056298      Macro  219.568184\n",
       "...    ...        ...           ...        ...         ...\n",
       "4433  50.0  22.728177      3.794120       Mega  184.040212\n",
       "4448  82.0  28.920430      3.213067      Micro  285.392143\n",
       "4452  36.0  15.393056      3.601162       Nano  119.220715\n",
       "4477  61.0  20.789544      2.473938      Macro  225.822151\n",
       "4569  44.0  19.800072      5.096192      Micro  163.631457\n",
       "\n",
       "[219 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ols1.outlier_test()['unadj_p'] < 0.05).sum()\n",
    "q3[ols1.outlier_test()['unadj_p'] < 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TV              3.562570\n",
       "Social_Media    0.004964\n",
       "Radio          -0.003970\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols1.params\n",
    "params1=ols1.params.drop('Intercept')\n",
    "params1.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bestc\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Sales</td>      <th>  R-squared:         </th> <td>   0.999</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.999</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>1.505e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 11 Dec 2021</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:10:29</td>     <th>  Log-Likelihood:    </th> <td> -11366.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4546</td>      <th>  AIC:               </th> <td>2.274e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4542</td>      <th>  BIC:               </th> <td>2.277e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>        <td>   -0.1340</td> <td>    0.103</td> <td>   -1.303</td> <td> 0.193</td> <td>   -0.336</td> <td>    0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TV</th>           <td>    3.5626</td> <td>    0.003</td> <td> 1051.118</td> <td> 0.000</td> <td>    3.556</td> <td>    3.569</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Radio</th>        <td>   -0.0040</td> <td>    0.010</td> <td>   -0.406</td> <td> 0.685</td> <td>   -0.023</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Social_Media</th> <td>    0.0050</td> <td>    0.025</td> <td>    0.199</td> <td> 0.842</td> <td>   -0.044</td> <td>    0.054</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.056</td> <th>  Durbin-Watson:     </th> <td>   1.998</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.972</td> <th>  Jarque-Bera (JB):  </th> <td>   0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.001</td> <th>  Prob(JB):          </th> <td>   0.983</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.013</td> <th>  Cond. No.          </th> <td>    149.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  Sales   R-squared:                       0.999\n",
       "Model:                            OLS   Adj. R-squared:                  0.999\n",
       "Method:                 Least Squares   F-statistic:                 1.505e+06\n",
       "Date:                Sat, 11 Dec 2021   Prob (F-statistic):               0.00\n",
       "Time:                        10:10:29   Log-Likelihood:                -11366.\n",
       "No. Observations:                4546   AIC:                         2.274e+04\n",
       "Df Residuals:                    4542   BIC:                         2.277e+04\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "const           -0.1340      0.103     -1.303      0.193      -0.336       0.068\n",
       "TV               3.5626      0.003   1051.118      0.000       3.556       3.569\n",
       "Radio           -0.0040      0.010     -0.406      0.685      -0.023       0.015\n",
       "Social_Media     0.0050      0.025      0.199      0.842      -0.044       0.054\n",
       "==============================================================================\n",
       "Omnibus:                        0.056   Durbin-Watson:                   1.998\n",
       "Prob(Omnibus):                  0.972   Jarque-Bera (JB):                0.034\n",
       "Skew:                          -0.001   Prob(JB):                        0.983\n",
       "Kurtosis:                       3.013   Cond. No.                         149.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx=q3[x_list]\n",
    "xx2=add_constant(xx)\n",
    "\n",
    "ols2=OLS(q3.Sales, xx2).fit()\n",
    "ols2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6718 entries, 0 to 6717\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   LOCATION  6718 non-null   object \n",
      " 1   SUBJECT   6718 non-null   object \n",
      " 2   TIME      6718 non-null   int64  \n",
      " 3   Value     6718 non-null   float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 210.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(PATH + 'Dataset_04.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOCATION    0\n",
       "SUBJECT     0\n",
       "TIME        0\n",
       "Value       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['LOCATION', 'SUBJECT', 'TIME', 'Value'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 1.한국인의 1인당 육류 소비량이 해가 갈수록 증가하는 것으로 보여 상관분석을 통하여\n",
    "# 확인하려고 한다. \n",
    "# - 데이터 파일로부터 한국 데이터만 추출한다. 한국은 KOR로 표기되어 있다.\n",
    "# - 년도별 육류 소비량 합계를 구하여 TIME과 Value간의 상관분석을 수행하고\n",
    "# 상관계수를 소수점 셋째 자리에서 반올림하여 소수점 둘째 자리까지만 기술하시오. \n",
    "# (답안 예시) 0.55\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "q1 = data.copy()\n",
    "print(q1.columns)\n",
    "q1_tab = q1[q1.LOCATION == 'KOR'].reset_index(drop = True).copy()\n",
    "round(pd.pivot_table(q1_tab, values = 'Value', index = 'TIME', aggfunc = 'sum').reset_index().corr().TIME['Value'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BEEF' 'PIG' 'POULTRY' 'SHEEP']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    POULTRY\n",
       "Name: sub, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 2. 한국 인근 국가 가운데 식생의 유사성이 상대적으로 높은 일본(JPN)과 비교하여, 연도별\n",
    "# 소비량에 평균 차이가 있는지 분석하고자 한다.\n",
    "# - 두 국가의 육류별 소비량을 연도기준으로 비교하는 대응표본 t 검정을 수행하시오.\n",
    "# - 두 국가 간의 연도별 소비량 차이가 없는 것으로 판단할 수 있는 육류 종류를 모두\n",
    "# 적으시오. (알파벳 순서) (답안 예시) BEEF, PIG, POULTRY, SHEEP\n",
    "# =============================================================================\n",
    "q2 = data[data.LOCATION.isin(['KOR','JPN'])]\n",
    "sub_list = q2.SUBJECT.unique()\n",
    "print(sub_list)\n",
    "from scipy.stats import ttest_rel\n",
    "q2_out=[]\n",
    "for i in sub_list:\n",
    "    temp=q2[q2.SUBJECT == i]\n",
    "    q2_tab=pd.pivot_table(temp, index='TIME',\n",
    "                         columns='LOCATION',\n",
    "                         values='Value').dropna()\n",
    "    ttest_out=ttest_rel(q2_tab.JPN, q2_tab.KOR)\n",
    "    pvalue=ttest_out.pvalue\n",
    "    q2_out.append([i, pvalue])\n",
    "q2_out=pd.DataFrame(q2_out, columns=['sub', 'pvalue'])    \n",
    "q2_out[q2_out.pvalue >= 0.05]['sub']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub</th>\n",
       "      <th>r2_score</th>\n",
       "      <th>mape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BEEF</td>\n",
       "      <td>0.835456</td>\n",
       "      <td>7.310893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PIG</td>\n",
       "      <td>0.940681</td>\n",
       "      <td>5.634980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POULTRY</td>\n",
       "      <td>0.951498</td>\n",
       "      <td>5.783358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SHEEP</td>\n",
       "      <td>0.004083</td>\n",
       "      <td>33.347966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sub  r2_score       mape\n",
       "0     BEEF  0.835456   7.310893\n",
       "1      PIG  0.940681   5.634980\n",
       "2  POULTRY  0.951498   5.783358\n",
       "3    SHEEP  0.004083  33.347966"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 3.(한국만 포함한 데이터에서) Time을 독립변수로, Value를 종속변수로 하여 육류\n",
    "# 종류(SUBJECT) 별로 회귀분석을 수행하였을 때, 가장 높은 결정계수를 가진 모델의\n",
    "# 학습오차 중 MAPE를 반올림하여 소수점 둘째 자리까지 기술하시오. (답안 예시) 21.12\n",
    "# (MAPE : Mean Absolute Percentage Error, 평균 절대 백분율 오차)\n",
    "# (MAPE = Σ ( | y - y ̂ | / y ) * 100/n ))\n",
    "# \n",
    "# =============================================================================\n",
    "q3 = data[data.LOCATION.isin(['KOR'])]\n",
    "sub_list = q3.SUBJECT.unique()\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "q3_out=[]\n",
    "for i in sub_list:\n",
    "    temp=q3[q3.SUBJECT == i]\n",
    "    lm=LinearRegression().fit(temp[['TIME']],temp['Value']) # 데이터셋 2차 구조\n",
    "    pred=lm.predict(temp[['TIME']])\n",
    "    r2_score=lm.score(temp[['TIME']],temp['Value'])\n",
    "    mape=(abs(temp['Value'] - pred)/temp['Value']).sum()*100/len(temp)\n",
    "    q3_out.append([i, r2_score, mape])\n",
    "q3_out=pd.DataFrame(q3_out, columns=['sub', 'r2_score', 'mape'])\n",
    "ind=q3_out.r2_score.idxmax()\n",
    "q3_out.iloc[ind, -1]\n",
    "q3_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8068 entries, 0 to 8067\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   ID               8068 non-null   int64  \n",
      " 1   Age              8068 non-null   int64  \n",
      " 2   Age_gr           8068 non-null   int64  \n",
      " 3   Gender           8068 non-null   int64  \n",
      " 4   Work_Experience  7239 non-null   float64\n",
      " 5   Family_Size      7733 non-null   float64\n",
      " 6   Ever_Married     8068 non-null   int64  \n",
      " 7   Graduated        8068 non-null   int64  \n",
      " 8   Profession       8068 non-null   int64  \n",
      " 9   Spending_Score   8068 non-null   int64  \n",
      " 10  Var_1            8068 non-null   int64  \n",
      " 11  Segmentation     8066 non-null   object \n",
      "dtypes: float64(2), int64(9), object(1)\n",
      "memory usage: 756.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(PATH + 'Dataset_05.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'Age', 'Age_gr', 'Gender', 'Work_Experience', 'Family_Size',\n",
      "       'Ever_Married', 'Graduated', 'Profession', 'Spending_Score', 'Var_1',\n",
      "       'Segmentation'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1166"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 1.위의 표에 표시된 데이터 타입에 맞도록 전처리를 수행하였을 때, 데이터 파일 내에\n",
    "# 존재하는 결측값은 모두 몇 개인가? 숫자형 데이터와 문자열 데이터의 결측값을\n",
    "# 모두 더하여 답하시오.\n",
    "# (String 타입 변수의 경우 White Space(Blank)를 결측으로 처리한다) (답안 예시) 123\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "q1 = data.copy()\n",
    "print(q1.columns)\n",
    "q1.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 2.이어지는 분석을 위해 결측값을 모두 삭제한다. 그리고, 성별이 세분화(Segmentation)에\n",
    "# 영향을 미치는지 독립성 검정을 수행한다. 수행 결과, p-value를 반올림하여 소수점\n",
    "# 넷째 자리까지 쓰고, 귀무가설을 기각하면 Y로, 기각할 수 없으면 N으로 기술하시오. \n",
    "# (답안 예시) 0.2345, N\n",
    "# =============================================================================\n",
    "q2 = data.dropna().reset_index(drop=True).copy()\n",
    "q2_tab=pd.crosstab(index=q2.Gender, columns=q2.Segmentation)\n",
    "from scipy.stats import chi2_contingency\n",
    "# q2['Segmentation+'] = q2.Segmentation\n",
    "# q2_tab = q2.pivot_table(index = 'Gender', columns = 'Segmentation+', values = 'Segmentation', aggfunc='count')\n",
    "q2_out=chi2_contingency(q2_tab)\n",
    "round(q2_out[1],4) < 0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6807116104868914"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 3.Segmentation 값이 A 또는 D인 데이터만 사용하여 의사결정 나무 기법으로 분류\n",
    "# 정확도를\n",
    "# 측정해 본다. \n",
    "# - 결측치가 포함된 행은 제거한 후 진행하시오.\n",
    "# - Train대 Test 7대3으로 데이터를 분리한다. (Seed = 123)\n",
    "# - Train 데이터를 사용하여 의사결정나무 학습을 수행하고, Test 데이터로 평가를\n",
    "# 수행한다.\n",
    "# - 의사결정나무 학습 시, 다음과 같이 설정하시오:\n",
    "# • Feature: Age_gr, Gender, Work_Experience, Family_Size, \n",
    "#             Ever_Married, Graduated, Spending_Score\n",
    "# • Label : Segmentation\n",
    "# • Parameter : Gini / Max Depth = 7 / Seed = 123\n",
    "# 이 때 전체 정확도(Accuracy)를 소수점 셋째 자리 이하는 버리고 소수점 둘째자리까지\n",
    "# 기술하시오.\n",
    "# (답안 예시) 0.12\n",
    "# =============================================================================\n",
    "q3 = data.dropna().reset_index(drop = True).copy()\n",
    "q3_tab = q3[q3.Segmentation.isin(['A', 'D'])].reset_index(drop=True)\n",
    "x_list = ['Age_gr', 'Gender', 'Work_Experience', 'Family_Size', 'Ever_Married', 'Graduated', 'Spending_Score']\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train,test=train_test_split(q3_tab, test_size=0.3, random_state=123)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt=DecisionTreeClassifier(max_depth=7, random_state=123)\n",
    "dt.fit(train[x_list], train['Segmentation'])\n",
    "dt.score(test[x_list], test['Segmentation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4323 entries, 0 to 4322\n",
      "Data columns (total 19 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   id             4323 non-null   int64  \n",
      " 1   date           4323 non-null   object \n",
      " 2   price          4323 non-null   float64\n",
      " 3   bedrooms       4323 non-null   int64  \n",
      " 4   bathrooms      4323 non-null   float64\n",
      " 5   sqft_living    4323 non-null   int64  \n",
      " 6   sqft_lot       4323 non-null   int64  \n",
      " 7   floors         4323 non-null   float64\n",
      " 8   waterfront     4323 non-null   int64  \n",
      " 9   view           4323 non-null   int64  \n",
      " 10  condition      4323 non-null   int64  \n",
      " 11  grade          4323 non-null   int64  \n",
      " 12  sqft_above     4323 non-null   int64  \n",
      " 13  sqft_basement  4323 non-null   int64  \n",
      " 14  yr_built       4323 non-null   int64  \n",
      " 15  yr_renovated   4323 non-null   int64  \n",
      " 16  zipcode        4323 non-null   int64  \n",
      " 17  sqft_living15  4323 non-null   int64  \n",
      " 18  sqft_lot15     4323 non-null   int64  \n",
      "dtypes: float64(3), int64(15), object(1)\n",
      "memory usage: 641.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(PATH + 'Dataset_06.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'date', 'price', 'bedrooms', 'bathrooms', 'sqft_living',\n",
      "       'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n",
      "       'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n",
      "       'sqft_living15', 'sqft_lot15'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1167272"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 1.강변 조망이 가능한지 여부(waterfront)에 따라 평균 주택 가격을 계산하고 조망이\n",
    "# 가능한 경우와 그렇지 않은 경우의 평균 가격 차이의 절대값을 구하시오. 답은\n",
    "# 소수점 이하는 버리고 정수부만 기술하시오. (답안 예시) 1234567\n",
    "# =============================================================================\n",
    "q1 = data.copy()\n",
    "print(q1.columns)\n",
    "int(q1[q1.waterfront == 1].price.mean() - q1[q1.waterfront == 0].price.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sqft_living', 'yr_built')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 2.price, bedrooms, bathrooms, sqft_living, sqft_lot, floors, yr_built 등 7개의 변수 간의\n",
    "# 상관분석을 수행하고 price와의 상관계수의 절대값이 가장 큰 변수와 가장 작은\n",
    "# 변수를 차례로 기술하시오. (답안 예시) view, zipcode\n",
    "# \n",
    "# =============================================================================\n",
    "x_list = ['price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'yr_built']\n",
    "q2 = data[x_list].copy()\n",
    "q2.corr().price.drop(['price']).idxmax(), q2.corr().price.drop(['price']).idxmin()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th> <td>   0.681</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.680</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   656.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 11 Dec 2021</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:21:22</td>     <th>  Log-Likelihood:    </th> <td> -58960.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4323</td>      <th>  AIC:               </th> <td>1.180e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4308</td>      <th>  BIC:               </th> <td>1.180e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    14</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>     <td> 6.302e+06</td> <td> 2.95e+05</td> <td>   21.401</td> <td> 0.000</td> <td> 5.73e+06</td> <td> 6.88e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bedrooms</th>      <td>  -2.5e+04</td> <td> 3680.510</td> <td>   -6.791</td> <td> 0.000</td> <td>-3.22e+04</td> <td>-1.78e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bathrooms</th>     <td> 5.179e+04</td> <td> 7163.408</td> <td>    7.230</td> <td> 0.000</td> <td> 3.77e+04</td> <td> 6.58e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_living</th>   <td>   92.3081</td> <td>    5.074</td> <td>   18.192</td> <td> 0.000</td> <td>   82.360</td> <td>  102.256</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_lot</th>      <td>    0.0054</td> <td>    0.093</td> <td>    0.059</td> <td> 0.953</td> <td>   -0.176</td> <td>    0.187</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>floors</th>        <td> 3.748e+04</td> <td> 8141.392</td> <td>    4.604</td> <td> 0.000</td> <td> 2.15e+04</td> <td> 5.34e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>waterfront</th>    <td> 6.277e+05</td> <td> 3.91e+04</td> <td>   16.064</td> <td> 0.000</td> <td> 5.51e+05</td> <td> 7.04e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>view</th>          <td>  4.04e+04</td> <td> 4797.344</td> <td>    8.421</td> <td> 0.000</td> <td>  3.1e+04</td> <td> 4.98e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>condition</th>     <td> 1.571e+04</td> <td> 5317.387</td> <td>    2.954</td> <td> 0.003</td> <td> 5280.918</td> <td> 2.61e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade</th>         <td> 1.306e+05</td> <td> 4700.604</td> <td>   27.789</td> <td> 0.000</td> <td> 1.21e+05</td> <td>  1.4e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_above</th>    <td>   33.7358</td> <td>    4.981</td> <td>    6.773</td> <td> 0.000</td> <td>   23.971</td> <td>   43.501</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_basement</th> <td>   58.5722</td> <td>    5.840</td> <td>   10.030</td> <td> 0.000</td> <td>   47.123</td> <td>   70.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yr_built</th>      <td>-3666.8957</td> <td>  150.805</td> <td>  -24.316</td> <td> 0.000</td> <td>-3962.551</td> <td>-3371.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yr_renovated</th>  <td>   17.7032</td> <td>    8.265</td> <td>    2.142</td> <td> 0.032</td> <td>    1.499</td> <td>   33.908</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_living15</th> <td>   23.0114</td> <td>    7.561</td> <td>    3.044</td> <td> 0.002</td> <td>    8.188</td> <td>   37.834</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_lot15</th>    <td>   -0.2323</td> <td>    0.142</td> <td>   -1.637</td> <td> 0.102</td> <td>   -0.511</td> <td>    0.046</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>2170.721</td> <th>  Durbin-Watson:     </th> <td>   2.011</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>38362.875</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 1.971</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>17.051</td>  <th>  Cond. No.          </th> <td>1.41e+17</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 8.13e-22. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.681\n",
       "Model:                            OLS   Adj. R-squared:                  0.680\n",
       "Method:                 Least Squares   F-statistic:                     656.0\n",
       "Date:                Sat, 11 Dec 2021   Prob (F-statistic):               0.00\n",
       "Time:                        10:21:22   Log-Likelihood:                -58960.\n",
       "No. Observations:                4323   AIC:                         1.180e+05\n",
       "Df Residuals:                    4308   BIC:                         1.180e+05\n",
       "Df Model:                          14                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================\n",
       "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "Intercept      6.302e+06   2.95e+05     21.401      0.000    5.73e+06    6.88e+06\n",
       "bedrooms        -2.5e+04   3680.510     -6.791      0.000   -3.22e+04   -1.78e+04\n",
       "bathrooms      5.179e+04   7163.408      7.230      0.000    3.77e+04    6.58e+04\n",
       "sqft_living      92.3081      5.074     18.192      0.000      82.360     102.256\n",
       "sqft_lot          0.0054      0.093      0.059      0.953      -0.176       0.187\n",
       "floors         3.748e+04   8141.392      4.604      0.000    2.15e+04    5.34e+04\n",
       "waterfront     6.277e+05   3.91e+04     16.064      0.000    5.51e+05    7.04e+05\n",
       "view            4.04e+04   4797.344      8.421      0.000     3.1e+04    4.98e+04\n",
       "condition      1.571e+04   5317.387      2.954      0.003    5280.918    2.61e+04\n",
       "grade          1.306e+05   4700.604     27.789      0.000    1.21e+05     1.4e+05\n",
       "sqft_above       33.7358      4.981      6.773      0.000      23.971      43.501\n",
       "sqft_basement    58.5722      5.840     10.030      0.000      47.123      70.021\n",
       "yr_built      -3666.8957    150.805    -24.316      0.000   -3962.551   -3371.241\n",
       "yr_renovated     17.7032      8.265      2.142      0.032       1.499      33.908\n",
       "sqft_living15    23.0114      7.561      3.044      0.002       8.188      37.834\n",
       "sqft_lot15       -0.2323      0.142     -1.637      0.102      -0.511       0.046\n",
       "==============================================================================\n",
       "Omnibus:                     2170.721   Durbin-Watson:                   2.011\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            38362.875\n",
       "Skew:                           1.971   Prob(JB):                         0.00\n",
       "Kurtosis:                      17.051   Cond. No.                     1.41e+17\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 8.13e-22. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 3. id, date, 그리고 zipcode를 제외한 모든 변수를 독립변수로, price를 종속변수로 하여\n",
    "# 회귀분석을 수행하시오. 통계적 유의성을 갖지 못하는 독립변수를 제거하면 회귀\n",
    "# 모형에 남는 변수는 모두\n",
    "# 몇 개인가? 이 때 음의 회귀계수를 가지는 변수는 몇 개인가? (답안 예시) 5, 3\n",
    "# =============================================================================\n",
    "\n",
    "# =============================================================================\n",
    "# (참고)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.formula.api import ols\n",
    "# =============================================================================\n",
    "q3 = data.drop(['id', 'date', 'zipcode'], axis = 1).copy()\n",
    "var_list = q3.columns.drop('price')\n",
    "formula = 'price~'+'+'.join(var_list)\n",
    "ols = ols(formula = formula, data = q3).fit()\n",
    "ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3_out = ols.pvalues\n",
    "q3_out_list=q3_out.index[q3_out < 0.05] \n",
    "q3_param=ols.params[q3_out_list]\n",
    "len(q3_param[q3_param < 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial_No          400 non-null    int64  \n",
      " 1   GRE                400 non-null    int64  \n",
      " 2   TOEFL              400 non-null    int64  \n",
      " 3   University_Rating  400 non-null    int64  \n",
      " 4   SOP                400 non-null    float64\n",
      " 5   LOR                400 non-null    float64\n",
      " 6   CGPA               400 non-null    float64\n",
      " 7   Research           400 non-null    int64  \n",
      " 8   Chance_of_Admit    400 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 28.2 KB\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(PATH + 'Dataset_07.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8733"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ['Serial_No', 'GRE', 'TOEFL', 'University_Rating', 'SOP', 'LOR', 'CGPA',\n",
    "#        'Research', 'Chance_of_Admit']\n",
    "# =============================================================================\n",
    "# 1. 합격 가능성에 GRE, TOEFL, CGPA 점수 가운데 가장 영향이 큰 것이 어떤 점수인지\n",
    "# 알아 보기 위해서 상관 분석을 수행한다.\n",
    "# - 피어슨(Pearson) 상관계수 값을 구한다.\n",
    "# - Chance_of_Admit와의 가장 큰 상관계수 값을 가지는 항목의 상관계수를 소수점 넷째\n",
    "# 자리에서 반올림하여 셋째 자리까지 기술하시오. (답안 예시) 0.123\n",
    "# =============================================================================\n",
    "x_list = ['GRE', 'TOEFL', 'CGPA', 'Chance_of_Admit']\n",
    "q1 = data[x_list].copy()\n",
    "round(abs(q1.corr().Chance_of_Admit.drop('Chance_of_Admit')).max(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.443291692470982"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 2.GRE 점수의 평균 이상을 받은 그룹과 평균 미만을 받은 그룹의 CGPA 평균은 차이가\n",
    "# 있는지\n",
    "# 검정을 하고자 한다.\n",
    "# - 적절한 검정 방법을 선택하고 양측 검정을 수행하시오 (등분산으로 가정)\n",
    "# - 검정 결과, 검정통계량의 추정치를 소수점 셋째 자리에서 반올림하여 소수점 두 자리까지\n",
    "# 기술하시오.\n",
    "# (답안 예시) 1.23\n",
    "# =============================================================================\n",
    "q2 = data.copy()\n",
    "mu=q2['GRE'].mean()\n",
    "q2['GRE_gr']=np.where(q2.GRE >= mu, 1, 0)\n",
    "g1=q2[q2.GRE_gr == 1]['CGPA']\n",
    "g0=q2[q2.GRE_gr == 0]['CGPA']\n",
    "from scipy.stats import ttest_ind\n",
    "q2_out=ttest_ind(g1, g0, equal_var=True)\n",
    "q2_out.statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRE                 -0.089023\n",
       "TOEFL                0.107847\n",
       "University_Rating    0.061670\n",
       "SOP                 -0.243508\n",
       "LOR                  1.007925\n",
       "CGPA                 1.955354\n",
       "Research             0.674606\n",
       "dtype: float64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 3.Chance_of_Admit 확률이 0.5를 초과하면 합격으로, 이하이면 불합격으로 구분하고\n",
    "# 로지스틱 회귀분석을 수행하시오.\n",
    "# - 원데이터만 사용하고, 원데이터 가운데 Serial_No와 Label은 모형에서 제외\n",
    "# - 각 설정값은 다음과 같이 지정하고, 언급되지 않은 사항은 기본 설정값을 사용하시오\n",
    "# Seed : 123\n",
    "# - 로지스틱 회귀분석 수행 결과에서 로지스틱 회귀계수의 절대값이 가장 큰 변수와 그 값을\n",
    "# 기술하시오. \n",
    "# (로지스틱 회귀계수는 반올림하여 소수점 둘째 자리까지 / Intercept는 제외)\n",
    "# (답안 예시) abc, 0.12\n",
    "# =============================================================================\n",
    "q3=data.copy()\n",
    "\n",
    "q3['Ch_cd']=np.where(q3.Chance_of_Admit > 0.5 , 1, 0)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "x_list=data.columns.drop(['Serial_No','Chance_of_Admit'])\n",
    "\n",
    "logit=LogisticRegression(fit_intercept=False, \n",
    "                         random_state=12, solver = 'liblinear')\n",
    "\n",
    "logit.fit(q3[x_list], q3['Ch_cd'])\n",
    "#abs(logit.coef_).max() # 1.955355062462584\n",
    "\n",
    "logit.coef_.shape\n",
    "q3_out=pd.Series(logit.coef_.reshape(-1))\n",
    "\n",
    "q3_out.index=x_list\n",
    "# q3_out.abs().nlargest(1)\n",
    "q3_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RandD_Spend      50 non-null     float64\n",
      " 1   Administration   50 non-null     float64\n",
      " 2   Marketing_Spend  50 non-null     float64\n",
      " 3   State            50 non-null     object \n",
      " 4   Profit           50 non-null     float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(PATH + 'Dataset_08.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.34, 0.32, 0.34])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 1.각 주(State)별 데이터 구성비를 소수점 둘째 자리까지 구하고, 알파벳 순으로\n",
    "# 기술하시오(주 이름 기준).\n",
    "# (답안 예시) 0.12, 0.34, 0.54\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "q1 = data.copy()\n",
    "q1['State'].value_counts(normalize=True).sort_index().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14868"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 2.주별 이익의 평균을 구하고, 평균 이익이 가장 큰 주와 작은 주의 차이를 구하시오. \n",
    "# 차이값은 소수점 이하는 버리고 정수부분만 기술하시오. (답안 예시) 1234\n",
    "# =============================================================================\n",
    "q2_tab=pd.pivot_table(data=q2,\n",
    "               index='State',\n",
    "               values='Profit', aggfunc='mean')\n",
    "int(q2_tab.max() - q2_tab.min()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(MAPE    Florida\n",
       " dtype: object,\n",
       " MAPE    5.707\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 3.독립변수로 RandD_Spend, Administration, Marketing_Spend를 사용하여 Profit을 주별로\n",
    "# 예측하는 회귀 모형을 만들고, 이 회귀모형을 사용하여 학습오차를 산출하시오.\n",
    "# - 주별로 계산된 학습오차 중 MAPE 기준으로 가장 낮은 오차를 보이는 주는 어느\n",
    "# 주이고 그 값은 무엇인가? (반올림하여 소수점 둘째 자리까지 기술하시오)\n",
    "# - (MAPE = Σ ( | y - y ̂ | / y ) * 100/n )\n",
    "# (답안 예시) ABC, 1.56\n",
    "# =============================================================================\n",
    "q3 = data.copy()\n",
    "state_list = q3.State.unique()\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "x_list = ['RandD_Spend', 'Administration', 'Marketing_Spend']\n",
    "mape_list = []\n",
    "for x in state_list:\n",
    "    q3_tab = q3[q3.State == x].drop('State', axis = 1)\n",
    "    lm.fit(q3_tab[x_list], q3_tab.Profit)\n",
    "    pred = lm.predict(q3_tab[x_list])\n",
    "    q3_out = q3_tab.copy()\n",
    "    q3_out['Profit_pred'] = pred\n",
    "    q3_out['result'] = abs((q3_out['Profit'] - q3_out['Profit_pred']) / q3_out['Profit'])\n",
    "    MAPE = q3_out.result.sum() * (100/len(q3_out))\n",
    "    mape_list.append(MAPE)\n",
    "q3_result = pd.DataFrame(mape_list, columns=['MAPE'])\n",
    "q3_result.index = state_list\n",
    "q3_result.idxmin(), round(q3_result.min() ,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 16 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   satisfaction                2000 non-null   object \n",
      " 1   Gender                      2000 non-null   object \n",
      " 2   Age                         2000 non-null   float64\n",
      " 3   Customer_Type               2000 non-null   object \n",
      " 4   Class                       2000 non-null   object \n",
      " 5   Flight_Distance             2000 non-null   float64\n",
      " 6   Seat_comfort                2000 non-null   float64\n",
      " 7   Food_and_drink              2000 non-null   float64\n",
      " 8   Inflight_wifi_service       2000 non-null   float64\n",
      " 9   Inflight_entertainment      2000 non-null   float64\n",
      " 10  Onboard_service             2000 non-null   float64\n",
      " 11  Leg_room_service            2000 non-null   float64\n",
      " 12  Baggage_handling            2000 non-null   float64\n",
      " 13  Cleanliness                 2000 non-null   float64\n",
      " 14  Departure_Delay_in_Minutes  2000 non-null   float64\n",
      " 15  Arrival_Delay_in_Minutes    1995 non-null   float64\n",
      "dtypes: float64(12), object(4)\n",
      "memory usage: 250.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(PATH + 'Dataset_09.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 1.데이터 타입을 위 표에 정의된 타입으로 전처리를 한 후, 데이터 파일 내에 결측값은\n",
    "# 총 몇 개인가? (답안 예시) 1\n",
    "# =============================================================================\n",
    "q1 = data.isnull().sum().sum()\n",
    "q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1068.632582\n",
       "Name: chi, dtype: float64"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 2.다음에 제시된 데이터 처리를 하고 카이제곱 독립성 검정을 수행하시오.\n",
    "# - 결측값이 있다면 해당 행을 제거하시오.\n",
    "# - 나이는 20 이하이면 10, 30 이하이면 20, 40 이하이면 30, 50 이하이면 40, 60 이하이면 50, \n",
    "# 60 초과는 60으로 변환하여 Age_gr으로 파생변수를 생성하시오.\n",
    "# - Age_gr, Gender, Customer_Type, Class 변수가 satisfaction에 영향이 있는지 카이제곱\n",
    "# 독립성 검정을 수행하시오. \n",
    "# - 연관성이 있는 것으로 파악된 변수의 검정통계량 추정치를 정수 부분만 기술하시오. \n",
    "# (답안 예시) 123\n",
    "# =============================================================================\n",
    "q2=data.copy()\n",
    "q2.columns\n",
    "\n",
    "import numpy as np\n",
    "q2['Age_gr']=np.where(q2.Age <= 20, 10,\n",
    "                np.where(q2.Age <= 30, 20,\n",
    "                   np.where(q2.Age <= 40, 30,\n",
    "                     np.where(q2.Age <= 50, 40,\n",
    "                        np.where(q2.Age <= 60, 50,  60)))))\n",
    "\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "\n",
    "# - Age_gr, Gender, Customer_Type, Class 변수가 satisfaction에 영향이 있는지\n",
    "var_list=['Age_gr', 'Gender', 'Customer_Type', 'Class']\n",
    "\n",
    "q2_out=[]\n",
    "for i in var_list:\n",
    "    q2_tab=pd.crosstab(index=q2[i], columns=q2['satisfaction'])\n",
    "    chi, pvalue, *_=chi2_contingency(q2_tab)\n",
    "    q2_out.append([i, chi, pvalue])\n",
    "\n",
    "q2_out=pd.DataFrame(q2_out, columns=['var', 'chi', 'pvalue'])\n",
    "\n",
    "q2_out[q2_out.pvalue < 0.05]['chi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bestc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7488721804511279"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 3.고객 만족도를 라벨로 하여 다음과 같이 로지스틱 회귀분석을 수행하시오. \n",
    "# - 결측치가 포함된 행은 제거\n",
    "# - 데이터를 7대 3으로 분리 (Seed = 123)\n",
    "# - 아래의 11개 변수를 Feature로 사용\n",
    "# Flight_Distance, Seat_comfort, Food_and_drink, Inflight_wifi_service, \n",
    "# Inflight_entertainment,Onboard_service, Leg_room_service, Baggage_handling,\n",
    "# Cleanliness, Departure_Delay_in_Minutes, Arrival_Delay_in_Minutes\n",
    "# \n",
    "# - Seed = 123, 이외의 항목은 모두 Default 사용\n",
    "# - 예측 정확도를 측정하고 dissatisfied의 f1 score를 소수점 넷째 자리에서 반올림하여\n",
    "# 소수점 셋째 자리까지 기술하시오. (답안 예시) 0.123\n",
    "# =============================================================================\n",
    "q3 = data.dropna().reset_index(drop=True).copy()\n",
    "x_list = ['Flight_Distance', 'Seat_comfort', 'Food_and_drink', 'Inflight_wifi_service', \n",
    "          'Inflight_entertainment','Onboard_service', 'Leg_room_service', 'Baggage_handling',\n",
    "          'Cleanliness', 'Departure_Delay_in_Minutes', 'Arrival_Delay_in_Minutes']\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(q3[x_list], q3.satisfaction, test_size = 0.3, random_state = 123)\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "f1_score(y_test, y_pred, pos_label='dissatisfied')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7801204819277109"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "\n",
    "x_var=['Flight_Distance', 'Seat_comfort', 'Food_and_drink',\n",
    "       'Inflight_wifi_service','Inflight_entertainment', 'Onboard_service', \n",
    "       'Leg_room_service', 'Baggage_handling', 'Cleanliness',\n",
    "       'Departure_Delay_in_Minutes', 'Arrival_Delay_in_Minutes']\n",
    "\n",
    "q3=data.dropna()\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(q3[x_var], q3['satisfaction'], \n",
    "                 test_size = 0.3, random_state = 123)\n",
    "\n",
    "\n",
    "model = LogisticRegression(solver = 'liblinear',random_state=123)\n",
    "result = model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "f1_score(y_test, y_pred, pos_label='dissatisfied')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 169 entries, 0 to 168\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   YEAR_MONTH  169 non-null    object \n",
      " 1   SOCIAL      169 non-null    float64\n",
      " 2   TV          169 non-null    float64\n",
      " 3   NEWSPAPER   169 non-null    float64\n",
      " 4   SALES_AMT   169 non-null    float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.7+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('C:/Workspace/python/TIL/Self-Study/복습 및 자습/ProDS/data/01_ADS_Sample_1.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['YEAR_MONTH', 'SOCIAL', 'TV', 'NEWSPAPER', 'SALES_AMT'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('TV', 0.183)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.columns)\n",
    "q1 = data.drop('YEAR_MONTH', axis = 1).copy()\n",
    "q1_out = abs(q1.corr().SALES_AMT.drop('SALES_AMT')).sort_values(ascending = False)\n",
    "q1_out.idxmax(), round(q1_out.max(), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.194"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2 = data.copy()\n",
    "q2['YEAR'] = q2['YEAR_MONTH'].apply(lambda x: x.split('-')[0]) \n",
    "q2['MONTH'] = q2['YEAR_MONTH'].apply(lambda x: x.split('-')[1])\n",
    "q2_tab = q2.drop('YEAR_MONTH', axis = 1)\n",
    "out1 = q2_tab[q2_tab.YEAR == '2009'].SALES_AMT.sum()\n",
    "out2 = q2_tab[q2_tab.YEAR == '2019'].SALES_AMT.sum()\n",
    "q2_out = ((out2 - out1) / out1) * 100\n",
    "round(q2_out, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.991"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3 = data.copy()\n",
    "q3['YEAR'] = q2['YEAR_MONTH'].apply(lambda x: x.split('-')[0]) \n",
    "q3['MONTH'] = q2['YEAR_MONTH'].apply(lambda x: x.split('-')[1])\n",
    "q3_tab = q2.drop('YEAR_MONTH', axis = 1)\n",
    "year_list = ['2009', '2019']\n",
    "q3_tab[q3_tab.YEAR.isin(year_list)].reset_index(drop=True)\n",
    "from scipy.stats import ttest_ind\n",
    "g1 = q3_tab[q3_tab.YEAR == '2009'].SALES_AMT\n",
    "g0 = q3_tab[q3_tab.YEAR == '2019'].SALES_AMT\n",
    "q3_out=ttest_ind(g1, g0, equal_var=True)\n",
    "round(q3_out.pvalue, 3)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fe3bab233825460445dbfeea6dcd52ef5815a3fa13c858fea07ac830aa383284"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
